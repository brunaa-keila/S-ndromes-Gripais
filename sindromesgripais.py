# -*- coding: utf-8 -*-
"""SindromesGripais3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11vIsBCEHxXQ7-u4VEnhbDLs0e4ib8X6r

# Projeto de mineração de dados

## Síndromes Gripais

### Dados

### Idade ->  0-1 referente as idades de 0-53.
###  Sexo -> Feminino = F, Masculino = M.
### DataNotificacao -> Mes -> 1-12
### Sintomas -> Tosse, Coriza, Dor de garganta, Dor de Cabeça, Distúrbios Olfativos, Distúrbios Gustativos, Dispneia, Febre. Onde Sim = 1 e Não = 0
### ClassificacaoFinal -> Confirmado: 0, Descartado: 1
"""

!pip install pycaret

!pip install joblib==1.3

import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import pycaret.classification as pc
import pycaret
import plotly.graph_objects as go
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

df = pd.read_csv('SindromesGripal-SE.csv', sep=';')

df.head()

df_dados = df[['sintomas', 'sexo', 'idade','dataNotificacao', 'classificacaoFinal']]

df_dados.head()

"""### Formatando a coluna sintomas"""

#Adicionando o espaço depois da virgula
#df_dados['sintomas'] = df_dados['sintomas'].str.replace(',  ', ',')
df_dados['sintomas'] = df_dados['sintomas'].str.replace(',', ', ')

df_dados.head()

"""## Verificamos quantidade de registros, colunas, tipos dos dados nas colunas e se há algum dado faltando."""

df_dados.info()
df_dados.isna().sum()

"""## Linhas duplicadas"""

duplicatas = df_dados[df_dados.duplicated()]
print(duplicatas)

"""## Valores sujos"""

valores_sujos = df_dados[df_dados.isnull().any(axis=1)]
print(valores_sujos)

"""## Valor maximo, minimo e média"""

df_dados.describe()

"""## Normalização dos dados

#### Criando colunas para cada atributo da coluna sintomas
"""

todos_sintomas = ['Tosse', 'Coriza', 'Dor de Garganta', 'Dor de Cabeça', 'Distúrbios Olfativos', 'Distúrbios Gustativos', 'Dispneia', 'Febre']

# Criar colunas para cada sintoma e inicializá-las com 0
for sintoma in todos_sintomas:
    df_dados[sintoma] = 0

# Preencher as colunas com base nos sintomas listados em cada linha
for i, row in df.iterrows():
    for sintoma in row['sintomas'].split(', '):
      df_dados.at[i, sintoma] = 1

df_dados.info()

df_dados.head()

df_dados.drop(columns= ['Assintomático', 'Outros'], inplace=True)

# exclusão de colunas desnecessarios
#nomes = []
#for i in range(13,18):
#    nomes.append(df_dados.columns[i])
#
#for n in nomes:
#    df_dados.drop(columns=n,inplace=True)

df_dados.drop(columns='sintomas', inplace = True)

df_dados.head()

"""### Formatando os dados de classificacaoFinal"""

df_dados['classificacaoFinal'].value_counts()

df_dados.loc[df_dados['classificacaoFinal'] == "Confirmado Laboratorial", 'classificacaoFinal'] = "Confirmado"
df_dados.loc[df_dados['classificacaoFinal'] == "Síndrome Gripal Não Especificada", 'classificacaoFinal'] = "Confirmado"
df_dados.loc[df_dados['classificacaoFinal'] == "Confirmado Clínico-Imagem", 'classificacaoFinal'] = "Confirmado"
df_dados.loc[df_dados['classificacaoFinal'] == "Confirmado Clínico-Epidemiológico", 'classificacaoFinal'] = "Confirmado"
df_dados.loc[df_dados['classificacaoFinal'] == "Confirmado por Critério Clínico", 'classificacaoFinal'] = "Confirmado"

df_dados.head()

"""### Normalizando os dados de IDADE"""

# Extrai a coluna de idade
idades = df_dados['idade'].values.reshape(-1, 1)

scaler = MinMaxScaler()

# Ajusta o scaler aos dados e transforma os dados
idades_normalizadas = scaler.fit_transform(idades)

# Adiciona as idade normalizadas ao DataFrame
df_dados['idade_normalizada'] = idades_normalizadas

df_dados.head()

df_dados.drop(columns='idade',inplace=True)

"""### Normalizando dados de SEXO"""

df_dados.loc[df_dados['sexo'] == "Masculino", 'sexo'] = "M"
df_dados.loc[df_dados['sexo'] == "Feminino", 'sexo'] = "F"

"""## Criando coluna mes"""

df_dados.dropna(inplace=True)

df_dados.isna()

df_dados['mes'] = df_dados['dataNotificacao'].apply(lambda atr1: int(str(atr1).split('/')[1]))

df_dados.head()

df_dados.drop(columns='dataNotificacao', inplace=True)

"""### Visualização do cabeçalho"""

df_dados.head()

"""### Verificamos quantidade de linhas, colunas, tipos dos dados nas colunas e se há algum dado faltando"""

df_dados.info()
df_dados.isna().sum()

"""### Linhas duplicadas"""

# Encontre linhas duplicadas
duplicatas = df_dados[df_dados.duplicated()]
print(duplicatas)

"""### Valores sujos"""

valores_sujos = df_dados[df_dados.isnull().any(axis=1)]
print(valores_sujos)

"""### Valor maximo, minimo e média"""

df_dados.describe()

"""## Outliers"""

fig = go.Figure()

fig.add_trace(go.Box(y = df_dados['idade_normalizada'], name = 'Sindrome Gripal'))

fig.show()

"""## Classificando os dados"""

df_treinamento = df_dados.sample(n=6000)
df_treinamento

pc.setup(data = df_treinamento, target='classificacaoFinal', n_jobs=None, transformation=True)
pc.compare_models(errors='raise')

# Melhor algoritmo baseado no F1
primeiro = pc.create_model('gbc')

tuned_lda = pc.tune_model(primeiro,optimize="F1")

# teste
df_teste = df_dados.sample(n=1000)
df_teste

unseen_predictions = pc.predict_model(primeiro, data=df_teste)
unseen_predictions.iloc[:,:].sample(n=7)

previsoes = unseen_predictions

accuracy = pc.pull()['Accuracy'].item()
auc = pc.pull()['AUC'].item()
recall = pc.pull()['Recall'].item()
precision = pc.pull()['Prec.'].item()
f1 = pc.pull()['F1'].item()
kappa = pc.pull()['Kappa'].item()
mcc = pc.pull()['MCC'].item()

print("Accuracy:", accuracy)
print("AUC:", auc)
print("Recall:", recall)
print("Precision:", precision)
print("F1:", f1)
print("Kappa:", kappa)
print("MCC:", mcc)

# Definindo as métricas e seus valores
metricas = ['Accuracy', 'AUC', 'Recall', 'Precision', 'F1', 'Kappa', 'MCC']
valores = [accuracy * 100, auc * 100, recall * 100, precision * 100, f1 * 100, kappa * 100, mcc * 100]

# Plotando o gráfico
plt.figure(figsize=(10, 6))
bars = plt.barh(metricas, valores, color='skyblue')

# Adicionando os valores de porcentagem no final de cada barra
for bar, valor in zip(bars, valores):
    plt.text(bar.get_width(), bar.get_y() + bar.get_height() / 2, f'{valor:.2f}%',
             va='center', ha='left')

plt.xlabel('Valor (%)')  # Atualizando o rótulo do eixo x para mostrar porcentagem
plt.title('Métricas de Avaliação do Modelo')
plt.gca().invert_yaxis()  # Inverter a ordem das métricas no eixo y
plt.show()

predicted_labels = unseen_predictions['prediction_label']
actual_labels = df_teste['classificacaoFinal']

correct_predictions = (predicted_labels == actual_labels).sum()
incorrect_predictions = (predicted_labels != actual_labels).sum()

total_predictions = len(predicted_labels)
accuracy_percentage = (correct_predictions / total_predictions) * 100
error_percentage = (incorrect_predictions / total_predictions) * 100

# Criar um gráfico de barras com os valores e porcentagens
plt.bar(['Corretas', 'Incorretas'], [correct_predictions, incorrect_predictions], color=['lightgreen', 'purple'])

# Adicionando as porcentagens acima das barras
plt.text(0, correct_predictions + 10, '{:.2f}%'.format(accuracy_percentage), ha='center')
plt.text(1, incorrect_predictions + 10, '{:.2f}%'.format(error_percentage), ha='center')

plt.title('Previsões Corretas vs. Incorretas')
plt.xlabel('Previsões')
plt.ylabel('Número de Observações')
plt.show()

unseen_predictions.info()

pc.plot_model(primeiro,'feature')

"""### Mês que tem mais casos confirmados"""

df_confirmados = df_teste.loc[df_teste['classificacaoFinal']== 'Confirmado']
df_confirmados_mes = df_confirmados.groupby(df_confirmados['mes'])['classificacaoFinal'].count()

#df_confirmados_mes
df_confirmados_mes.idxmax()